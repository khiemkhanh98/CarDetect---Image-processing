using namespace std;
#include "Blob.h"
#include <fstream>
#include <string>
#include <iomanip>
#pragma warning(disable : 4996)
#include<opencv2/core/core.hpp>
#include<opencv2/highgui/highgui.hpp>
#include<opencv2/imgproc/imgproc.hpp>
#include "opencv2/imgcodecs.hpp"
#include "opencv2/videoio.hpp"
#include <opencv2/video.hpp>
#include<iostream>
#include<conio.h>  // remove this line if not using Windows OS
#define SHOW_STEPS // un-comment | comment this line to show steps or not

// const global variables
const cv::Scalar SCALAR_BLACK = cv::Scalar(0.0, 0.0, 0.0);
const cv::Scalar SCALAR_WHITE = cv::Scalar(255.0, 255.0, 255.0);
const cv::Scalar SCALAR_YELLOW = cv::Scalar(0.0, 255.0, 255.0);
const cv::Scalar SCALAR_GREEN = cv::Scalar(0.0, 200.0, 0.0);
const cv::Scalar SCALAR_RED = cv::Scalar(0.0, 0.0, 255.0);

// function prototypes
void matchCurrentFrameBlobsToExistingBlobs(std::vector<Blob> &existingBlobs, std::vector<Blob> &currentFrameBlobs);
void addBlobToExistingBlobs(Blob &currentFrameBlob, std::vector<Blob> &existingBlobs, int &intIndex);
void addNewBlob(Blob &currentFrameBlob, std::vector<Blob> &existingBlobs);
double distanceBetweenPoints(cv::Point point1, cv::Point point2);
void drawAndShowContours(cv::Size imageSize, std::vector<std::vector<cv::Point> > contours, std::string strImageName);
void drawAndShowContours(cv::Size imageSize, std::vector<Blob> blobs, std::string strImageName, cv::Mat originalImage);
bool checkIfBlobsCrossedTheLineLeft(std::vector<Blob> &blobs, int &carCountLeft, double fps);
void drawBlobInfoOnImage(std::vector<Blob> &blobs, cv::Mat &imgFrame2Copy);
void drawCarCountOnImage(cv::Mat &imgFrame2Copy);


// global variables
std::stringstream date;
int carCountLeft = 0;
int prevFrameCount = 0;
double timeCount = 0.0;
int frameCount = 1;

cv::Mat frame; //current frame
cv::Mat imgThresh; //fg mask fg mask generated by MOG2 method
cv::Ptr<cv::BackgroundSubtractorMOG2> pMOG2; //MOG2 Background subtractor
int keyboard; //input from keyboard

int main(void) {
	cv::VideoCapture capVideo;
	cv::Mat imgFrame1;
	std::vector<Blob> blobs;
	cv::Point crossingLine[2];
	cv::Point crossingLineLeft[2];

	capVideo.open("C:/Users/User/Downloads/Video/Aerial Top Down View Shot of Traffic on a Car Bridge. Video - Stock Footage - Videohive - YouTube.MP4");
	double fps = capVideo.get(CV_CAP_PROP_FPS);

	if (!capVideo.isOpened()) {                                                 // if unable to open video file
		std::cout << "error reading video file" << std::endl << std::endl;      // show error message
		_getch();																// remove this line if not using Windows OS
		return(0);                                                              // and exit program
	}

	if (capVideo.get(CV_CAP_PROP_FRAME_COUNT) < 2) {
		std::cout << "error: video file must have at least two frames";
		_getch();																// remove this line if not using Windows OS
		return(0);
	}

	cv::namedWindow("FG Mask MOG 2");

	//create Background Subtractor objects
	pMOG2 = cv::createBackgroundSubtractorMOG2(500, 16.0, 1); //MOG2 approach

	capVideo.read(imgFrame1);
	cout << "Width : " << imgFrame1.cols << endl;
	cout << "Height: " << imgFrame1.rows << endl;
	//CONTROL LINE FOR CARCOUNT ~AREA2 (LEFT WAY)
	crossingLineLeft[0].x = 500;
	crossingLineLeft[0].y = 280;

	crossingLineLeft[1].x = 500;
	crossingLineLeft[1].y = 400;

	char chCheckForEscKey = 0;
	bool blnFirstFrame = true;


	while (capVideo.isOpened() && chCheckForEscKey != 27) {
		std::vector<Blob> currentFrameBlobs;
		cv::Mat imgFrame1Copy = imgFrame1.clone();


		cv::cvtColor(imgFrame1Copy, imgFrame1Copy, CV_BGR2GRAY);
		cv::GaussianBlur(imgFrame1Copy, imgFrame1Copy, cv::Size(5, 5), 0);
		cv::Mat frame = imgFrame1Copy.clone();
		pMOG2->apply(frame, imgThresh, 0.005);


		cv::imshow("FG Mask MOG 2", imgThresh);
		cv::blur(imgThresh, imgThresh, cv::Size(15, 15), cv::Point(-1, -1));
		cv::blur(imgThresh, imgThresh, cv::Size(15, 15), cv::Point(-1, -1));
		cv::threshold(imgThresh, imgThresh, 130, 255, cv::THRESH_BINARY);
		cv::imshow("after Thresh", imgThresh);
		cv::Mat imgThreshCopy = imgThresh.clone();
		std::vector<std::vector<cv::Point> > contours;
		cv::findContours(imgThreshCopy, contours, cv::RETR_EXTERNAL, cv::CHAIN_APPROX_SIMPLE);

		drawAndShowContours(imgThresh.size(), contours, "imgContours");

		std::vector<std::vector<cv::Point> > convexHulls(contours.size());

		for (unsigned int i = 0; i < contours.size(); i++) {
			cv::convexHull(contours[i], convexHulls[i]);
		}

		drawAndShowContours(imgThresh.size(), convexHulls, "imgConvexHulls");

		for (auto &convexHull : convexHulls) {
			Blob possibleBlob(convexHull);
			currentFrameBlobs.push_back(possibleBlob);
		}

		//drawAndShowContours(imgThresh.size(), currentFrameBlobs, "imgCurrentFrameBlobs");

		if (blnFirstFrame == true) {
			for (auto &currentFrameBlob : currentFrameBlobs) {
				blobs.push_back(currentFrameBlob);
			}
		}
		else {
			matchCurrentFrameBlobsToExistingBlobs(blobs, currentFrameBlobs);
		}



		imgFrame1Copy = imgFrame1.clone();	// get another copy of frame 2 since we changed the previous frame 2 copy in the processing above
		drawAndShowContours(imgThresh.size(), blobs, "imgBlobs", imgFrame1Copy);

		drawBlobInfoOnImage(blobs, imgFrame1Copy);


		// Check the leftWay
		bool blnAtLeastOneBlobCrossedTheLineLeft = checkIfBlobsCrossedTheLineLeft(blobs, carCountLeft, fps);

		//rightWay

		//leftway
		if (blnAtLeastOneBlobCrossedTheLineLeft == true) {
			cv::line(imgFrame1Copy, crossingLineLeft[0], crossingLineLeft[1], SCALAR_WHITE, 2);
		}
		else if (blnAtLeastOneBlobCrossedTheLineLeft == false) {
			cv::line(imgFrame1Copy, crossingLineLeft[0], crossingLineLeft[1], SCALAR_YELLOW, 2);
		}

		drawCarCountOnImage(imgFrame1Copy);

		cv::imshow("imgFrame1Copy", imgFrame1Copy);

		cv::waitKey(0);	// uncomment this line to go frame by frame for debugging

						// now we prepare for the next iteration
		currentFrameBlobs.clear();

		if ((capVideo.get(CV_CAP_PROP_POS_FRAMES) + 1) < capVideo.get(CV_CAP_PROP_FRAME_COUNT)) {
			capVideo.read(imgFrame1);
		}
		else {
			std::cout << "end of video\n";
			break;
		}

		blnFirstFrame = false;
		frameCount++;
		chCheckForEscKey = cv::waitKey(1);
	}

	if (chCheckForEscKey != 27) {               // if the user did not press esc (i.e. we reached the end of the video)
		cv::waitKey(0);                         // hold the windows open to allow the "end of video" message to show
	}

	// note that if the user did press esc, we don't need to hold the windows open, we can simply let the program end which will close the windows
	return(0);
}


void matchCurrentFrameBlobsToExistingBlobs(std::vector<Blob> &existingBlobs, std::vector<Blob> &currentFrameBlobs) {
	for (auto &existingBlob : existingBlobs) {
		existingBlob.blnCurrentMatchFoundOrNewBlob = false;
		existingBlob.predictNextPosition();
	}

	for (auto &currentFrameBlob : currentFrameBlobs) {
		int intIndexOfLeastDistance = 0;
		double dblLeastDistance = 100000.0;

		for (unsigned int i = 0; i < existingBlobs.size(); i++) {

			if (existingBlobs[i].blnStillBeingTracked == true) {
				double dblDistance = distanceBetweenPoints(currentFrameBlob.centerPositions.back(), existingBlobs[i].predictedNextPosition);

				if (dblDistance < dblLeastDistance) {
					dblLeastDistance = dblDistance;
					intIndexOfLeastDistance = i;
				}
			}
		}

		if (dblLeastDistance < currentFrameBlob.dblCurrentDiagonalSize * 0.5) {
			addBlobToExistingBlobs(currentFrameBlob, existingBlobs, intIndexOfLeastDistance);
		}
		else {
			addNewBlob(currentFrameBlob, existingBlobs);
		}

	}

	for (auto &existingBlob : existingBlobs) {
		if (existingBlob.blnCurrentMatchFoundOrNewBlob == false) {
			existingBlob.intNumOfConsecutiveFramesWithoutAMatch++;
		}
		if (existingBlob.intNumOfConsecutiveFramesWithoutAMatch >= 5) {
			existingBlob.blnStillBeingTracked = false;
		}
	}
}


void addBlobToExistingBlobs(Blob &currentFrameBlob, std::vector<Blob> &existingBlobs, int &intIndex) {
	existingBlobs[intIndex].currentContour = currentFrameBlob.currentContour;
	existingBlobs[intIndex].currentBoundingRect = currentFrameBlob.currentBoundingRect;
	existingBlobs[intIndex].centerPositions.push_back(currentFrameBlob.centerPositions.back());
	existingBlobs[intIndex].dblCurrentDiagonalSize = currentFrameBlob.dblCurrentDiagonalSize;
	existingBlobs[intIndex].dblCurrentAspectRatio = currentFrameBlob.dblCurrentAspectRatio;
	existingBlobs[intIndex].blnStillBeingTracked = true;
	existingBlobs[intIndex].blnCurrentMatchFoundOrNewBlob = true;
}


void addNewBlob(Blob &currentFrameBlob, std::vector<Blob> &existingBlobs) {
	currentFrameBlob.blnCurrentMatchFoundOrNewBlob = true;
	existingBlobs.push_back(currentFrameBlob);
}


double distanceBetweenPoints(cv::Point point1, cv::Point point2) {
	int intX = abs(point1.x - point2.x);
	int intY = abs(point1.y - point2.y);

	return(sqrt(pow(intX, 2) + pow(intY, 2)));
}


void drawAndShowContours(cv::Size imageSize, std::vector<std::vector<cv::Point> > contours, std::string strImageName) {
	cv::Mat image(imageSize, CV_8UC3, SCALAR_BLACK);
	cv::drawContours(image, contours, -1, SCALAR_WHITE, -1);
	cv::imshow(strImageName, image);
}


void drawAndShowContours(cv::Size imageSize, std::vector<Blob> blobs, std::string strImageName, cv::Mat originalImage) {
	cv::Mat image(imageSize, CV_8UC3, SCALAR_BLACK);
	std::vector<std::vector<cv::Point> > contours;

	for (auto &blob : blobs) {
		if (blob.blnStillBeingTracked == true) {
			contours.push_back(blob.currentContour);
		}
	}

	cv::drawContours(image, contours, -1, SCALAR_WHITE, -1);
	cv::imshow(strImageName, image);

}



bool checkIfBlobsCrossedTheLineLeft(std::vector<Blob> &blobs, int &carCountLeft, double fps) {
	bool blnAtLeastOneBlobCrossedTheLineLeft = false;

	for (auto blob : blobs) {
		if (blob.blnStillBeingTracked == true && blob.centerPositions.size() >= 2) {
			int prevFrameIndex = (int)blob.centerPositions.size() - 2;
			int currFrameIndex = (int)blob.centerPositions.size() - 1;
			// Left way
			if (blob.centerPositions[prevFrameIndex].x <= 500 && blob.centerPositions[currFrameIndex].x > 500 && blob.centerPositions[currFrameIndex].y < 450 && blob.centerPositions[currFrameIndex].y > 200) {
				carCountLeft++;
				blnAtLeastOneBlobCrossedTheLineLeft = true;
				timeCount = (frameCount - prevFrameCount) / fps;
				prevFrameCount = frameCount;
				cout << "luu luong: " << 1 / timeCount << endl;

			}
		}
	}

	return blnAtLeastOneBlobCrossedTheLineLeft;
}


void drawBlobInfoOnImage(std::vector<Blob> &blobs, cv::Mat &imgFrame2Copy) {
	for (unsigned int i = 0; i < blobs.size(); i++) {
		if (blobs[i].blnStillBeingTracked == true) {
			cv::rectangle(imgFrame2Copy, blobs[i].currentBoundingRect, SCALAR_RED, 2);

			int intFontFace = CV_FONT_HERSHEY_SIMPLEX;
			double dblFontScale = (imgFrame2Copy.rows * imgFrame2Copy.cols) / 300000.0;
			int intFontThickness = (int)std::round(dblFontScale * 1.0);

			//cv::putText(imgFrame2Copy, std::to_string(i), blobs[i].centerPositions.back(), intFontFace, dblFontScale, SCALAR_GREEN, intFontThickness);
		}
	}
}


void drawCarCountOnImage(cv::Mat &imgFrame2Copy) {
	int intFontFace = CV_FONT_HERSHEY_SIMPLEX;
	double dblFontScale = (imgFrame2Copy.rows * imgFrame2Copy.cols) / 450000.0;
	int intFontThickness = (int)std::round(dblFontScale * 2.5);

	// Right way


	// Left way
	cv::Size textSize1 = cv::getTextSize(std::to_string(carCountLeft), intFontFace, dblFontScale, intFontThickness, 0);

	cv::putText(imgFrame2Copy, "Flowrate:" + std::to_string(1 / timeCount), cv::Point(500, 50), intFontFace, dblFontScale, SCALAR_YELLOW, intFontThickness);
	cv::putText(imgFrame2Copy, "Cars:" + std::to_string(carCountLeft), cv::Point(10, 50), intFontFace, dblFontScale, SCALAR_YELLOW, intFontThickness);
}
//
///